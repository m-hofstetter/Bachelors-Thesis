\chapter{Evaluation}\label{chap:evaluation}

To evaluate my implementation of the FunArray, we will experimentally test it. We want to determine its effectiveness in determining loop invariants, as well as in asserting given proof obligations.

\section{Experimental Setup}
\subsection{Benchmarks}

The International Competition on Software Verification (or SV-COMP)\footnote{More information about SV-COMP available at \url{https://sv-comp.sosy-lab.org/}} provides a set of benchmarks that can be used to compare tools for software verification\footnote{Available at \url{https://gitlab.com/sosy-lab/benchmarking/sv-benchmarks}}. Their subcategory ``c/ReachSafety-Arrays'' contains a collection of 433 verification tasks written in C for which the treatment of arrays is necessary to determine reachability. As such, this collection is suitable to test my implementation of the FunArray. They include at least one assertion per benchmark and its expected verdict for testing.
The simple C programs have been translated to the embedded domain-specific language in Java using the tool Cuv\'ee \cite{ernst2020}. Since my implementation of the FunArray does not provide the entire functionality of the C language, about half of the benchmarks could not be translated. The 196 untranslatable benchmarks utilise features like the use of boolean variables, nested arrays, functions with a return value, structs and the use of the break keyword.

\subsection{Formal Arguments of the FunArray}

One of the FunArray's strengths is its ability to use different abstract domains for its bounds, array elements and variables without having to adapt the static analyser. For this evaluation the following abstract domains have been chosen as the FunArray functor's formal arguments: For abstracting variables and array elements the interval domain has been chosen, since it is relatively simple to implement. The chosen expression domain and therefore the abstract representation of segment bounds follows the scheme used by the FunArray's inventors \cite[section 7.2]{cousot2011}. Expressions are limited to the normal form $v+k$ where $v$ is a variable (whose value is abstracted by intervals) and $k$ is an integer constant.

\section{Results}

The execution time of the benchmarks is almost negligible. To execute all 237 benchmarks it takes 253 milliseconds (Averaged value over 100 runs. The workbench used is a M2 Max MacBook Pro running OpenJDK 22). This comes down to about a millisecond per benchmark. This result was expected, since the FunArray does not handle disjunctions separately but through the use of empty segments. No combinatorial explosion is expected to occur.

\subsection{Definition of Triviality}

We want to determine for how many of the benchmarks' loops the analyser is able to come up with an invariant. Since the analysis will always produce a result even if there is no meaningful information that can be extracted from it, we need to define triviality for these results. Consider an array $A$ for example. The analysis is run on some some loop and determines the invariant for $A$ to be \funArray{A:\bound{a} \fvalue{[-\infty,\infty]} \bound{a.length}?}. This basically tells us that $A$ contains integers whose value is entirely unknown on its entire length, or in other words: We know nothing at all about \texttt{A}. Therefore this invariant must be considered trivial. More generally, a state containing only arrays that themselves only contain segments of unknown value is certainly considered trivial.

What we consider non-trivial is however not as clear. It might seem intuitive to consider every state that does not fit this description as such, however this leaves out an important aspect: The FunArray analyser is able to fully automatically divide an array into semantic segments. This differentiates the FunArray from a technique called array smashing \cite{cousot2011}. An analysis employing array smashing treats all array elements homogeneously. When changing a single element value, its abstract value is joined with all other elements and a lot of information is lost that way. To evaluate in which cases the FunArray analyser beats the array smashing, we must consider two different types of non-triviality:

\begin{enumerate}
	\item The general case, where at least one array in a state contains at least one segment with a value more specific than $\top$.
	\item The more narrow case where at least one array is two or more segments long and at least one of these segments has a value more specific than $\top$.
\end{enumerate}

\noindent Of course it is not assured that we could have determined the same invariant via array smashing in the first case, but we certainly know that we could not have gotten the same result in the second case without the automatic semantic segmentation.


\subsection{Invariants}

Spread across the 238 benchmarks there are 947 loops. For 580 or 61.3\% of those my implementation of the FunArray was able to determine a general non-trivial invariant. When examining the more narrow requirements for non-triviality, we arrive at 427 invariants, which is still 45.0\% of the total, meaning the FunArray is able to generate at least four times as many non-trivial invariants as the array smashing technique. If we were to increase the required number of segments to more than two, this number would drop down to 3, suggesting the FunArrays ability to depict a lot of segments cannot be utilised in actual code analyses. No calculated invariants had more than three segments.

\subsection{Verifying assertions}

My implementation is able to correctly identify the result of 24 out of the 247 assertions spread among 237 benchmarks or 9.7\% of assertions. It did not contradict any proof obligations. When manually inspecting the program mechanism preceding these assertions in the benchmark, a single pattern can be identified that precedes the majority of them: Initialisation. The benchmark first initialises an array with a consistent value as its every element and immediately afterwards asserts that every element of the array has that specific value. Of the 24 correctly assessed assertions, 20 follow this pattern. The remaining four assertions follow a more complex program scheme, that involves conditions and loops. This suggests that one of the strengths of the FunArray is to recognise correct initialisation of arrays.



\section{Discussion}
\subsection{Comparison with Cousot, Cousot and Logozzo's Results}

Cousot, Cousot and Logozzo evaluate their implementation of the FunArray by analysing the main libraries of the .NET framework and the implementation itself \cite{cousot2011}. The .NET libraries have been chosen for this since they contain a large amount of code and a vast selection of functionalities and techniques. They, however, lack an important aspect: The specification of expected properties. The authors are able to infer thousands of invariants but cannot determine whether they actually provide any useful information for the further execution of the code. To check against pre-specified properties they annotated their implementation of the FunArray with pre-conditions and proof obligations and ran it on itself. They were able to correctly assert 61 out of 1800 or 3.4\% of proof obligations when analysing the FunArray implementation using itself \cite{cousot2011}. This roughly matches my results of 9.7\%, considering the easy initialisation assertions make up a way greater amount of my test cases than would be present in a real world program.

\subsection{Limitations}

\subsubsection{Adjacent potentially empty segments}
When expanding a segment by inserting a value adjacent to it, formerly adjacent and potentially empty segments will be joined with their nearest neighbour until a non-empty segment is reached. Let us consider the FunArray \funArray{A:\bound{a} \fvalue{x} \bound{b} \fvalue{y} \bound{c}? \fvalue{z} \bound{d}} for example. It is unknown whether its second segment containing the value $y$ is empty or not and thus whether $b=c$ or $b<c$ is true.
When trying to expand the first segment by inserting its value $x$ at index $b$, the resulting FunArray could either be \funArray{\bound{a} \fvalue{x} \bound{b\;c} \fvalue{x} \bound{b+1}? \fvalue{z} \bound{d}}, if the $y$-segment was empty, or alternatively \funArray{\bound{a} \fvalue{x} \bound{b} \fvalue{x} \bound{b+1} \fvalue{y} \bound{c}? \fvalue{z} \bound{d}}, if it was non-empty. Since the position of the \funArray{\bound{c}}-bound cannot by decided, it must be discarded altogether. After the insertion, $A$ becomes \funArray{A':\bound{a} \fvalue{x} \bound{b} \fvalue{x} \bound{b+1}? \fvalue{y\sqcup z} \bound{d}} and all information concerning the variable $c$ is lost.
Analyses of programs utilising segments in their arrays with adjacent and potentially empty segments have to discard non-trivial information. Thus the FunArray's approach for handling potentially empty adjacent segments limits the number of programs for which an analysis can achieve a non-trivial result. Consider the following program, a C implementation of Dijkstra's Dutch national flag algorithm \cite{dijkstra1976}, for example. This example is not one of the benchmarks, but rather an algorithm that I tried to run while debugging and which turned out to not be analysable by my implementation in a meaningful way.
 
\vspace{2mm}
\begin{center}
\begin{BVerbatim}
int A[] = {-1, 1, 0, 0, -1, -1, 1, 1, 0};
int length = sizeof(A) / sizeof(A[0]);

int r = 0;
int w = length - 1;
int b = length - 1;

while (r <= w) {
    if (A[w] <= -1) {
        int temp = A[r];
        A[r] = A[w];
        A[w] = temp;
        r++;
    } else if (A[w] == 0) {
        w--;
    } else {
        int temp = A[w];
        A[w] = A[b];
        A[b] = temp;
        w--;
        b--;
    }
}
\end{BVerbatim}
\end{center}
 
\noindent Even though the analysis correctly determines the Array to be described as $\bound{0} \fvalue{[-\infty, -1]} \bound{r}? \fvalue{\top} \bound{w}? \fvalue{[0, 0]} \bound{b}? \fvalue{[1, \infty]}  \bound{|A|}?$ after a single loop pass, it loses all its information in the second pass, because the determined segments are all potentially empty and extending their neighbours discards them altogether. After the second loop pass the analysis yields $\bound{0} \fvalue{\top} \bound{|A|}$. Basically no information can be gained. It might very well be possible that this behaviour is circumventable by introducing separate analyses for both cases. This experiment however, is outside of the scope of this thesis.
 
\subsubsection{Complex expressions in bounds}

The FunArray can only hold expressions in normal form in its bound. When inserting a value at a more complex index expression, a normalisation of that expression might not be possible. As it cannot be inserted, the information about its order is lost, or worse, when the segment bounds are then empty, even more informations is lost, since adjacent segments will have to be joined. To demonstrate this, let us have a look at an excerpt from the ``array\_doub\_access\_init\_\allowbreak{}const'' benchmark:


\begin{adjustbox}{center}
\begin{lstlisting}
int N=100000;
int a[2*N+2];

for(i=0;i<=N;i++) {
    a[2*i]=0;
    a[2*i+1]=0;
}
\end{lstlisting}
\end{adjustbox}
\vspace{2mm}

\noindent We would expect an analysis to determine that every element of \texttt{a} has the value \texttt{0} after executing this snippet. Unfortunately this is not the case. The analyser is not able to normalise the expressions \texttt{2*i} and \texttt{2*i+1} and therefore has to join all FunArray segments and thereby losing all information about the array.
 It might be hypothesised that shortcoming could be circumvented if the FunArray was able to hold arbitrary expressions in its bounds and not just those in a fixed normal form. Experimentally proving this was outside of the scope of this thesis and is left to future research.
 

\subsubsection{Sorted Arrays}

In the chosen benchmark selection there are some benchmarks in which an array is being sorted (e.g. ``sorting\_selectionsort\_ground\_1'', ``sorting\_bubblesort\_\allowbreak{}ground\_1'' etc.). Since my analyser does not employ relational values but is limited to intervals, it is not able assert whether an array is sorted or not. 
 For Cousot, Cousot and Logozzo's FunArray the array element abstract domain is not only an abstraction of the element value (like in my implementation), but rather an abstraction of the cross product between an index and an array element value \cite{cousot2011}. It might be possible to construct an abstract domain that ensures that the value of an array element is increasing with its index. In my research I could not find any hints on whether this has been tried yet. I can therefore merely hypothesise that this approach might allow the FunArray to proof an array being sorted. 
 
 
 
 
 
 
 
 
 
 
 
 

